{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prach\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import libraries for feature extraction, data splitting, and evaluation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Import necessary libraries for BERT model and tokenizer\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import models and preprocessing tools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the spaCy library for advanced text preprocessing\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Twitter dataset\n",
    "data = pd.read_csv(\"..\\Data\\TwitterData/twitter_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75682 entries, 0 to 75681\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweetID        75682 non-null  int64 \n",
      " 1   entity         75682 non-null  object\n",
      " 2   sentiment      75682 non-null  object\n",
      " 3   tweet_content  74996 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information for understanding its structure\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweetID       entity sentiment  \\\n",
       "0     2401  Borderlands  Positive   \n",
       "1     2401  Borderlands  Positive   \n",
       "2     2401  Borderlands  Positive   \n",
       "3     2401  Borderlands  Positive   \n",
       "4     2401  Borderlands  Positive   \n",
       "\n",
       "                                       tweet_content  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset for preview\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75682, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the dataset (rows and columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows to ensure uniqueness\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop rows with missing values to handle null data\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small English spaCy model for text preprocessing\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Define a preprocessing function to clean and lemmatize text\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        # Exclude stopwords and punctuation\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        # Append lemmatized version of the token\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    # Join tokens into a single string\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'tweet_content' column\n",
    "data['Preprocessed Text'] = data['tweet_content'].apply(preprocess) \n",
    "\n",
    "# Initialize the LabelEncoder for encoding target labels (sentiments)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the 'sentiment' column into numeric values\n",
    "data['sentiment'] = le.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Preprocessed Text'] = data['Preprocessed Text'].astype(str)  # Convert all to string\n",
    "data = data[data['Preprocessed Text'].str.strip() != '']  # Drop empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the dataset to balance class representation and reduce size\n",
    "data = data.groupby('sentiment', group_keys=False).apply(lambda x: x.sample(frac=5000/75682, random_state=42))\n",
    "\n",
    "# Separate features (text) and target (sentiment) columns\n",
    "X = data[\"Preprocessed Text\"]\n",
    "y = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation (50%) and test (50%) to get 10% each\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train: 3724, Length of y_train: 3724\n",
      "Length of X_val: 466, Length of y_val: 466\n",
      "Length of X_test: 466, Length of y_test: 466\n"
     ]
    }
   ],
   "source": [
    "# Print the lengths of the splits to ensure proper division\n",
    "print(f\"Length of X_train: {len(X_train)}, Length of y_train: {len(y_train)}\")\n",
    "print(f\"Length of X_val: {len(X_val)}, Length of y_val: {len(y_val)}\")\n",
    "print(f\"Length of X_test: {len(X_test)}, Length of y_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer for encoding text into numerical format\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum token length for truncation and padding\n",
    "max_len = 128\n",
    "\n",
    "# Tokenize and encode the training, validation, and test data\n",
    "X_train_encoded = tokenizer.batch_encode_plus(X.tolist(),\n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\ttruncation=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmax_length = max_len,\n",
    "\t\t\t\t\t\t\t\t\t\t\treturn_tensors='tf')\n",
    "\n",
    "X_val_encoded = tokenizer.batch_encode_plus(X_val.tolist(), \n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\ttruncation=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmax_length = max_len,\n",
    "\t\t\t\t\t\t\t\t\t\t\treturn_tensors='tf')\n",
    "\n",
    "X_test_encoded = tokenizer.batch_encode_plus(X_test.tolist(), \n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\ttruncation=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmax_length = max_len,\n",
    "\t\t\t\t\t\t\t\t\t\t\treturn_tensors='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prach\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model for sequence classification with 4 labels (sentiments)\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer, sparse categorical cross-entropy loss, and accuracy metric\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 1081s 7s/step - loss: 1.1266 - accuracy: 0.5316 - val_loss: 0.8989 - val_accuracy: 0.6459\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data and validate on the validation set\n",
    "history = model.fit(\n",
    "\t[X_train_encoded['input_ids'], X_train_encoded['token_type_ids'], X_train_encoded['attention_mask']],\n",
    "\ty,\n",
    "\tvalidation_data=(\n",
    "\t[X_val_encoded['input_ids'], X_val_encoded['token_type_ids'], X_val_encoded['attention_mask']],y_val),\n",
    "\tbatch_size=32,\n",
    "\tepochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 27s 2s/step - loss: 0.9238 - accuracy: 0.6567\n",
      "Test loss: 0.9238451719284058, Test accuracy: 0.6566523313522339\n",
      "Training accuracy: 0.531572163105011, Validation accuracy: 0.6459227204322815\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    [X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']],\n",
    "    y_test\n",
    ")\n",
    "\n",
    "# Extract training and validation accuracies from the history object\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "# Print evaluation results\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')\n",
    "print(f'Training accuracy: {train_accuracy}, Validation accuracy: {val_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 27s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the test data\n",
    "logits = model.predict([X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']]).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6529321843907155\n",
      "Recall: 0.6566523605150214\n",
      "F1 Score: 0.62117296794008\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.18      0.28       100\n",
      "           1       0.71      0.87      0.78       143\n",
      "           2       0.60      0.63      0.62       102\n",
      "           3       0.64      0.83      0.72       121\n",
      "\n",
      "    accuracy                           0.66       466\n",
      "   macro avg       0.65      0.63      0.60       466\n",
      "weighted avg       0.65      0.66      0.62       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax to logits to get probabilities for each class\n",
    "y_pred_probs = tf.nn.softmax(logits, axis=-1).numpy()\n",
    "\n",
    "# Convert probabilities to predicted labels\n",
    "if y_pred_probs.shape[1] == 2:  # Binary classification\n",
    "    y_pred = (y_pred_probs[:, 1] > 0.5).astype(int)\n",
    "else:  # Multi-class classification\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert test labels to numpy array for compatibility\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print classification metrics\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "Input Statement: hello\n",
      "Predicted Sentiment: Positive (Confidence: 0.52)\n"
     ]
    }
   ],
   "source": [
    "# Function for user-input prediction\n",
    "def predict_sentiment(statement):\n",
    "    processed_statement = preprocess(statement)  # Preprocess user input\n",
    "    encoded_statement = tokenizer.encode_plus(\n",
    "        processed_statement, max_length=max_len, padding='max_length', truncation=True, return_tensors='tf')\n",
    "    logits = model.predict([encoded_statement['input_ids'], encoded_statement['token_type_ids'], encoded_statement['attention_mask']]).logits\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1).numpy()\n",
    "    prediction = np.argmax(probabilities, axis=1)[0]  # Get the predicted label\n",
    "    sentiment_label = le.inverse_transform([prediction])[0]  # Decode label to original sentiment\n",
    "    print(f\"Input Statement: {statement}\")\n",
    "    print(f\"Predicted Sentiment: {sentiment_label} (Confidence: {probabilities[0][prediction]:.2f})\")\n",
    "\n",
    "# Example usage for user input\n",
    "user_input = input(\"Enter a statement to predict its sentiment: \")\n",
    "predict_sentiment(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
